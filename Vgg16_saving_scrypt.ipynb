{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "from Images import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "0.weight \t torch.Size([64, 3, 3, 3])\n",
      "0.bias \t torch.Size([64])\n",
      "2.weight \t torch.Size([64, 64, 3, 3])\n",
      "2.bias \t torch.Size([64])\n",
      "5.weight \t torch.Size([128, 64, 3, 3])\n",
      "5.bias \t torch.Size([128])\n",
      "7.weight \t torch.Size([128, 128, 3, 3])\n",
      "7.bias \t torch.Size([128])\n",
      "10.weight \t torch.Size([256, 128, 3, 3])\n",
      "10.bias \t torch.Size([256])\n",
      "12.weight \t torch.Size([256, 256, 3, 3])\n",
      "12.bias \t torch.Size([256])\n",
      "14.weight \t torch.Size([256, 256, 3, 3])\n",
      "14.bias \t torch.Size([256])\n",
      "16.weight \t torch.Size([256, 256, 3, 3])\n",
      "16.bias \t torch.Size([256])\n",
      "19.weight \t torch.Size([512, 256, 3, 3])\n",
      "19.bias \t torch.Size([512])\n",
      "21.weight \t torch.Size([512, 512, 3, 3])\n",
      "21.bias \t torch.Size([512])\n",
      "23.weight \t torch.Size([512, 512, 3, 3])\n",
      "23.bias \t torch.Size([512])\n",
      "25.weight \t torch.Size([512, 512, 3, 3])\n",
      "25.bias \t torch.Size([512])\n",
      "28.weight \t torch.Size([512, 512, 3, 3])\n",
      "28.bias \t torch.Size([512])\n",
      "30.weight \t torch.Size([512, 512, 3, 3])\n",
      "30.bias \t torch.Size([512])\n",
      "32.weight \t torch.Size([512, 512, 3, 3])\n",
      "32.bias \t torch.Size([512])\n",
      "34.weight \t torch.Size([512, 512, 3, 3])\n",
      "34.bias \t torch.Size([512])\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cnn = models.vgg19(pretrained=True).to(device).features.eval()\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in cnn.state_dict():\n",
    "    print(param_tensor, \"\\t\", cnn.state_dict()[param_tensor].size())\n",
    "\n",
    "for layer in cnn.children():\n",
    "    print (layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'test/vgg16.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "        batch_size , h, w, f_map_num = input.size()\n",
    "        features = input.view(batch_size * h, w * f_map_num)\n",
    "        G = torch.mm(features, features.t())\n",
    "        return G.div(batch_size * h * w * f_map_num)\n",
    "\n",
    "class ContentLoss(nn.Module):\n",
    "\n",
    "        def __init__(self, target,):\n",
    "            super(ContentLoss, self).__init__()\n",
    "            self.target = target.detach()\n",
    "            self.loss = F.mse_loss(self.target, self.target )\n",
    "\n",
    "        def forward(self, input):\n",
    "            self.loss = F.mse_loss(input, self.target)\n",
    "            return input\n",
    "\n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "        def __init__(self, target_feature):\n",
    "            super(StyleLoss, self).__init__()\n",
    "            self.target = gram_matrix(target_feature).detach()\n",
    "            self.loss = F.mse_loss(self.target, self.target)# to initialize with something\n",
    "\n",
    "        def forward(self, input):\n",
    "            G = gram_matrix(input)\n",
    "            self.loss = F.mse_loss(G, self.target)\n",
    "            return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "\n",
    "# normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
    "model = nn.Sequential()\n",
    "\n",
    "i = 0  # increment every time we see a conv\n",
    "for layer in cnn.children():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        i += 1\n",
    "        name = 'conv_{}'.format(i)\n",
    "    elif isinstance(layer, nn.ReLU):\n",
    "        name = 'relu_{}'.format(i)\n",
    "        # The in-place version doesn't play very nicely with the ContentLoss\n",
    "        # and StyleLoss we insert below. So we replace with out-of-place\n",
    "        # ones here.\n",
    "        #Переопределим relu уровень\n",
    "        layer = nn.ReLU(inplace=False)\n",
    "    elif isinstance(layer, nn.MaxPool2d):\n",
    "        name = 'pool_{}'.format(i)\n",
    "    elif isinstance(layer, nn.BatchNorm2d):\n",
    "        name = 'bn_{}'.format(i)\n",
    "    else:\n",
    "        raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "    model.add_module(name, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = nn.Sequential()\n",
    "for name, module in model.named_children():\n",
    "    new_model.add_module(name, module)\n",
    "    if name == 'conv_5':\n",
    "        new_model.add_module(name, module)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_1): ReLU()\n",
       "  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_2): ReLU()\n",
       "  (pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_3): ReLU()\n",
       "  (conv_4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_4): ReLU()\n",
       "  (pool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1.weight \t torch.Size([64, 3, 3, 3])\n",
      "conv_1.bias \t torch.Size([64])\n",
      "conv_2.weight \t torch.Size([64, 64, 3, 3])\n",
      "conv_2.bias \t torch.Size([64])\n",
      "conv_3.weight \t torch.Size([128, 64, 3, 3])\n",
      "conv_3.bias \t torch.Size([128])\n",
      "conv_4.weight \t torch.Size([128, 128, 3, 3])\n",
      "conv_4.bias \t torch.Size([128])\n",
      "conv_5.weight \t torch.Size([256, 128, 3, 3])\n",
      "conv_5.bias \t torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in new_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", new_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_model, './test/entire_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
